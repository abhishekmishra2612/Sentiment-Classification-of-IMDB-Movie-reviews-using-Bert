{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Bert_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LO6Bodoy_jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmU779id1mgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a5bb248-35cb-48c9-bb83-19952745155a"
      },
      "source": [
        "# importing dependencies use to this case study.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0DeqHn0-h2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ecf7210b-7c20-4131-d833-9102e5ee0178"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX-Kfqlf-N2c",
        "colab_type": "text"
      },
      "source": [
        "## Load IMDB Movie Reviews dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsCmFUf--gpX",
        "colab_type": "text"
      },
      "source": [
        "### Source:\n",
        "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIUopGdm46HV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e19a2cd3-497d-4d3d-ec72-cef555b35988"
      },
      "source": [
        "# Loading the IMDB dataset from drive.\n",
        "imdb_data = pd.read_csv('/content/drive/My Drive/IMDB Dataset.csv')\n",
        "print(imdb_data.shape)\n",
        "imdb_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xcqjCxFR8LA",
        "colab_type": "text"
      },
      "source": [
        "###**Text Preprocessing :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FrHeo3lspgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjUx9siu1LR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z.!]', ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK8T1Jhg8lVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = []\n",
        "for sentence in imdb_data['review'].values:\n",
        "  reviews.append(preprocess_text(sentence))\n",
        "reviews = np.array(reviews)  \n",
        "sentiment = np.array(list(map(lambda a:1 if a=='positive' else 0, imdb_data['sentiment'].values))) # Map positive to 1 and negative to 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnSlpd8o8lbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e1d05f7a-818e-4088-8d39-c87bbc387fe9"
      },
      "source": [
        "reviews[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked. They are right as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO. Trust me this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs sex or violence. Its is hardcore in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda. Em City is home to many..Aryans Muslims gangstas Latinos Christians Italians Irish and more....so scuffles death stares dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare. Forget pretty pictures painted for mainstream audiences forget charm forget romance...OZ doesn t mess around. The first episode I ever saw struck me as so nasty it was surreal I couldn t say I was ready for it but as I watched more I developed a taste for Oz and got accustomed to the high levels of graphic violence. Not just violence but injustice crooked guards who ll be sold out for a nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience Watching Oz you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.',\n",
              "       'A wonderful little production. The filming technique is very unassuming very old time BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master s of comedy and his life. The realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets particularly of their flat with Halliwell s murals decorating every surface are terribly well done.',\n",
              "       'I thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a light hearted comedy. The plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer . While some may be disappointed when they realize this is not Match Point Risk Addiction I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.This was the most I d laughed at one of Woody s comedies in years dare I say a decade . While I ve never been impressed with Scarlet Johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young woman.This may not be the crown jewel of his career but it was wittier than Devil Wears Prada and more interesting than Superman a great comedy to go see with friends.',\n",
              "       'Basically there s a family where a little boy Jake thinks there s a zombie in his closet his parents are fighting all the time.This movie is slower than a soap opera... and suddenly Jake decides to become Rambo and kill the zombie.OK first of all when you re going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie and instead i watched a drama with some meaningless thriller spots. out of just for the well playing parents descent dialogs. As for the shots with Jake just ignore them.',\n",
              "       'Petter Mattei s Love in the Time of Money is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money power and success do to people in the different situations we encounter. This being a variation on the Arthur Schnitzler s play about the same theme the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way or another to the next person but no one seems to know the previous point of contact. Stylishly the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounter.The acting is good under Mr. Mattei s direction. Steve Buscemi Rosario Dawson Carol Kane Michael Imperioli Adrian Grenier and the rest of the talented cast make these characters come alive.We wish Mr. Mattei good luck and await anxiously for his next work.'],\n",
              "      dtype='<U13458')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-r_mM5r_Au6",
        "colab_type": "text"
      },
      "source": [
        "## Split dataset: 40000 for train and 10000 for test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy9NHJ4S8lea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "x_train, x_test, y_train, y_test = train_test_split(reviews, sentiment, test_size = 0.2, stratify = sentiment, random_state = 42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5jBaXsO8lZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "94f4234e-4c9d-455c-8357-ed143141340b"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n",
            "(40000,)\n",
            "(10000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj1OpWmPKxbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del imdb_data, reviews, sentiment # delete data that will not use "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiU91e4D8lXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0b94aaee-318a-480d-84bd-a50f4244c86e"
      },
      "source": [
        "x_train[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['I caught this little gem totally by accident back in or . I was at a revival theatre to see two old silly sci fi movies. The theatre was packed full and with no warning they showed a bunch of sci fi short spoofs to get us in the mood . Most were somewhat amusing but THIS came on and within seconds the audience was in hysterics! The biggest laugh came when they showed Princess Laia having huge cinnamon buns instead of hair on her head. She looks at the camera gives a grim smile and nods. That made it even funnier! You gotta see Chewabacca played by what looks like a Muppet! It was extremely silly and stupid...but I couldn t stop laughing. Most of the dialogue was drowned out because of all the laughter. Also if you know Star Wars pretty well it s even funnier they deliberately poke fun at some of the dialogue. This REALLY works with an audience! A definite !',\n",
              "       'I can t believe that I let myself into this movie to accomplish a favor my friends ask me early this April . This movie certainly a pain in your ass in theater and sickly boring I haven t even felt the gory impact of its daunting scenes which I deem to be complete failure to attract its audience. The worst even trampled me cause my friend failed to come on time at the theater because she was busy assisting her boyfriend in looking for an appropriate lodge to stay in for one night. I wasn t really disappointed with that matter but this movie is a matter indeed for me poor plot useless storyline naively created and I don t know what to say anymore.The title doesn t suggest anyway the creeps and horror it failed to overture us viewers maybe the beating of the animals could get more the creeps if they show it in theaters the real situational play. Good luck to anyone who attempts to watch it anyway.',\n",
              "       ' spoiler alert! it just gets to me the nerve some people have to remake and i use the term loosely here.. good movies. in the american version of this dutch thriller someone decided the original ending wasn t pasteurized enough for american audiences. so what do they do they create a new one! a stupid improbable i pretend i m dead but come to life again so the good guy can kick my butt some more kind of ending. do yourself a favor and get the original one.',\n",
              "       'If there s one thing I ve learnt from watching George Romero s Creepshow it s that if you stumble upon an mysterious old crate that someone has obviously gone to a lot of effort to hide just leave well alone there s probably something nasty inside.Obviously Professor Gordon Crowley Robert Englund s character in Jack Brooks Monster Slayer isn t a Romero fan cos he busts open the old wooden box he finds buried in his yard only to discover surprise surprise an ancient demon that possesses his body initially causing him to eat and vomit rather a lot .When the demon eventually erupts from Crowley s body during chemistry class and begins to transform the students into hellish flesh tearing beasts it s up to plumber Jack Brooks Trevor Matthews to try and stop the foul creatures armed only with a length of pipe and fuelled by a lifelong hatred of all things monstrous!.The DVD packaging for Jon Knautz s low budget monster flick promises one hell of a fun ride offering cheesy thrills and spills of the kind one might expect from your average s creature feature toothy critters rubber monster suits gruesome gore and absolutely no CGI! and for the last minutes that s exactly what viewers get non stop splattery effects a silly tentacled Jabba style demon thingy and mucho macho monster mashing!It s a shame then that the rest of the film s running time a massive minutes or so is mostly spent following Jack as he goes about his boring everyday business plumbing visiting his shrink going to chemistry class and upsetting his girlfriend. If you think you might enjoy a film that focuses primarily on coping with childhood trauma and anger management buying spare boiler valves from a hardware shop and the chemical properties of Sodium then this is the film for you but if it s a massive dose of monster mayhem you re after then I d advise looking elsewhere!',\n",
              "       'I remember when this was in theaters reviews said it was horrible. Well I didn t think it was that bad. It was amusing and had a lot of tongue in cheek humor concerning families around holiday time.Ben Affleck is a rich guy who needs to find a family for Christmas to please his girlfriend. He goes to visit the house he grew up in and strikes a deal to rent the family there for Christmas. I really liked the lawyer scene where they sign a contract. That was funny.So he makes silly requests of the family and even writes scripts for them to read. Of course the family has a hot daughter for the love interest. And he learns that the holidays aren t so bad after all.Also the whole doo dah act was funny especially when they replaced the first one with a black guy and the girlfriends s parents didn t even say anything about it. And the parts where doo dah is hitting on his supposed daughter. FINAL VERDICT I thought it s worth checking out if you catch it on cable.'],\n",
              "      dtype='<U13458')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eOHCtIO_bzn",
        "colab_type": "text"
      },
      "source": [
        "## Load the pretrained Bert model to extract features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_59IoYDyaZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp3jz6VHFvTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distil_bert = 'distilbert-base-uncased' # Name of the pretrained models : (Wights)\n",
        "\n",
        "#DistilBERT \n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert)\n",
        "model = TFDistilBertModel.from_pretrained(distil_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l430Y23F_6Wt",
        "colab_type": "text"
      },
      "source": [
        "### Some toy examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds_i6EQ8FvWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0ff640ba-2763-413f-8bd3-fc55ed5cdc44"
      },
      "source": [
        "e = tokenizer.encode(\"You'll come back tomorrow. !\")\n",
        "print(e)\n",
        "print(\"=\"*50)\n",
        "print(tokenizer.decode(e))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2017, 1005, 2222, 2272, 2067, 4826, 1012, 999, 102]\n",
            "==================================================\n",
            "[CLS] you'll come back tomorrow.! [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJZq6VNFvbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4775434e-1da5-46ba-c58e-c28282a74004"
      },
      "source": [
        "e = tokenizer.encode(x_train[0])\n",
        "print(e)\n",
        "print(\"=\"*100)\n",
        "print(tokenizer.decode(e))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1045, 3236, 2023, 2210, 17070, 6135, 2011, 4926, 2067, 1999, 2030, 1012, 1045, 2001, 2012, 1037, 6308, 3004, 2000, 2156, 2048, 2214, 10021, 16596, 10882, 5691, 1012, 1996, 3004, 2001, 8966, 2440, 1998, 2007, 2053, 5432, 2027, 3662, 1037, 9129, 1997, 16596, 10882, 2460, 11867, 21511, 2015, 2000, 2131, 2149, 1999, 1996, 6888, 1012, 2087, 2020, 5399, 19142, 2021, 2023, 2234, 2006, 1998, 2306, 3823, 1996, 4378, 2001, 1999, 1044, 27268, 22420, 2015, 999, 1996, 5221, 4756, 2234, 2043, 2027, 3662, 4615, 21110, 2050, 2383, 4121, 21229, 21122, 2015, 2612, 1997, 2606, 2006, 2014, 2132, 1012, 2016, 3504, 2012, 1996, 4950, 3957, 1037, 11844, 2868, 1998, 11232, 1012, 2008, 2081, 2009, 2130, 4569, 14862, 999, 2017, 10657, 2156, 21271, 19736, 16665, 2209, 2011, 2054, 3504, 2066, 1037, 14163, 29519, 999, 2009, 2001, 5186, 10021, 1998, 5236, 1012, 1012, 1012, 2021, 1045, 2481, 1056, 2644, 5870, 1012, 2087, 1997, 1996, 7982, 2001, 12805, 2041, 2138, 1997, 2035, 1996, 7239, 1012, 2036, 2065, 2017, 2113, 2732, 5233, 3492, 2092, 2009, 1055, 2130, 4569, 14862, 2027, 9969, 26202, 4569, 2012, 2070, 1997, 1996, 7982, 1012, 2023, 2428, 2573, 2007, 2019, 4378, 999, 1037, 15298, 999, 102]\n",
            "====================================================================================================\n",
            "[CLS] i caught this little gem totally by accident back in or. i was at a revival theatre to see two old silly sci fi movies. the theatre was packed full and with no warning they showed a bunch of sci fi short spoofs to get us in the mood. most were somewhat amusing but this came on and within seconds the audience was in hysterics! the biggest laugh came when they showed princess laia having huge cinnamon buns instead of hair on her head. she looks at the camera gives a grim smile and nods. that made it even funnier! you gotta see chewabacca played by what looks like a muppet! it was extremely silly and stupid... but i couldn t stop laughing. most of the dialogue was drowned out because of all the laughter. also if you know star wars pretty well it s even funnier they deliberately poke fun at some of the dialogue. this really works with an audience! a definite! [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fheScmFzKf6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "668186b3-aa0b-4fb2-95ab-b06f7f852525"
      },
      "source": [
        "len(e)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGvtXN4jFvg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "281b88ac-ae1e-4d7a-d34d-97ba27ad001e"
      },
      "source": [
        "output = model(tf.constant(e)[None, :])\n",
        "print(type(output))\n",
        "output"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 194, 768), dtype=float32, numpy=\n",
              " array([[[ 0.15895611, -0.12386137,  0.05420507, ..., -0.03344058,\n",
              "           0.55348414,  0.3435394 ],\n",
              "         [ 0.52001077, -0.32365903, -0.01601099, ...,  0.00661454,\n",
              "           0.69623977,  0.25855684],\n",
              "         [-0.06160792, -0.22191559,  0.34980658, ..., -0.09395681,\n",
              "           0.01518752, -0.37404358],\n",
              "         ...,\n",
              "         [ 0.37388927, -0.07064627,  0.42436817, ..., -0.3785236 ,\n",
              "           0.39427185, -0.38435003],\n",
              "         [-0.04955504, -0.14920276,  0.03789302, ...,  0.22821037,\n",
              "           0.4417211 , -0.4650039 ],\n",
              "         [ 0.54786795,  0.3371322 ,  0.3964695 , ...,  0.41849664,\n",
              "           0.20822771, -0.2171463 ]]], dtype=float32)>,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qltNpJBFvtZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51177458-6850-4325-8f75-a209a3ff7855"
      },
      "source": [
        "len(output[0][0][2])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryQM04RdMd48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ead806bd-6db1-41bd-aafd-17a1c37dd2cf"
      },
      "source": [
        "max_len = 0\n",
        "for sent in x_train:\n",
        "  l = len(sent)\n",
        "  if l>max_len:\n",
        "    max_len = l\n",
        "print(max_len)    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaeLU4syRfxN",
        "colab_type": "text"
      },
      "source": [
        "##**Feature Extraction using pretrained Bert :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tET5RqAMuell",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable = False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAnwdH5wFvl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caf86eaa-0836-4ff4-b979-c6c1c8ae039c"
      },
      "source": [
        "# Features extraction for train.\n",
        "X_train = []\n",
        "for sent in x_train:\n",
        "  if len(sent) >= 512:\n",
        "    sent = sent[:510]\n",
        "  e = tokenizer.encode(sent)\n",
        "  output = model(tf.constant(e)[None, :])\n",
        "  X_train.append(output[0][0][0])\n",
        "X_train = np.array(X_train) \n",
        "print(X_train.shape) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_blWuaFi6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/X_train_imdb.npy', X_train)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjW6yGGMFvwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8c7d25f-63e4-45da-85a9-1d7a41f71530"
      },
      "source": [
        "# Feature extraction for test.\n",
        "from tqdm import tqdm\n",
        "X_test = []\n",
        "for sent in tqdm(x_test):\n",
        "  if len(sent) >= 512:\n",
        "    sent = sent[:510]\n",
        "  e = tokenizer.encode(sent)\n",
        "  output = model(tf.constant(e)[None, :])\n",
        "  X_test.append(output[0][0][0])\n",
        "X_test = np.array(X_test) \n",
        "print(X_test.shape)\n",
        "np.save('/content/drive/My Drive/X_test_imdb.npy', X_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [10:09<00:00, 16.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPflI9UZFv04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d00b88dd-243c-4279-e4ee-5a7b129fc53a"
      },
      "source": [
        "X_train = np.load('/content/drive/My Drive/X_train_imdb.npy')\n",
        "X_test = np.load('/content/drive/My Drive/X_test_imdb.npy')\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 768)\n",
            "(10000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUWZi6V6ARKm",
        "colab_type": "text"
      },
      "source": [
        "## Fully connected Neural nets Architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIg0G5mLAhrA",
        "colab_type": "text"
      },
      "source": [
        "### To train on the features that extracted from pretrained Bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtBeQza2Fv5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "1e075c87-d0a7-4d3f-afeb-dd284a1b116c"
      },
      "source": [
        "input_layer = tf.keras.layers.Input(shape=(768, ))\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='elu', kernel_initializer='he_normal')(input_layer)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='elu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(512, activation='elu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='elu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='elu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='elu', kernel_initializer='he_normal')(x)\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "clf_model = tf.keras.models.Model(input_layer, output_layer)\n",
        "\n",
        "clf_model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,838,081\n",
            "Trainable params: 1,838,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t188AhuFvzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model.\n",
        "clf_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PViSyHz-WH3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callbacks.\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/IMDB_review_clf_Model', verbose=1, save_best_only=True)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyONwFB9Fvuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e775086-926e-42c6-e4a4-e4b1296f97c6"
      },
      "source": [
        "# Train model.\n",
        "history = clf_model.fit(X_train,y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test), callbacks=[earlystopper, checkpointer])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "304/313 [============================>.] - ETA: 0s - loss: 0.8164 - accuracy: 0.6030\n",
            "Epoch 00001: val_loss improved from inf to 0.54366, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8091 - accuracy: 0.6065 - val_loss: 0.5437 - val_accuracy: 0.7550\n",
            "Epoch 2/100\n",
            "302/313 [===========================>..] - ETA: 0s - loss: 0.5127 - accuracy: 0.7576\n",
            "Epoch 00002: val_loss improved from 0.54366 to 0.42734, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5118 - accuracy: 0.7579 - val_loss: 0.4273 - val_accuracy: 0.8100\n",
            "Epoch 3/100\n",
            "299/313 [===========================>..] - ETA: 0s - loss: 0.4738 - accuracy: 0.7811\n",
            "Epoch 00003: val_loss did not improve from 0.42734\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4737 - accuracy: 0.7810 - val_loss: 0.4427 - val_accuracy: 0.8118\n",
            "Epoch 4/100\n",
            "305/313 [============================>.] - ETA: 0s - loss: 0.4545 - accuracy: 0.7894\n",
            "Epoch 00004: val_loss did not improve from 0.42734\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.7893 - val_loss: 0.4275 - val_accuracy: 0.8151\n",
            "Epoch 5/100\n",
            "301/313 [===========================>..] - ETA: 0s - loss: 0.4445 - accuracy: 0.7959\n",
            "Epoch 00005: val_loss improved from 0.42734 to 0.42351, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4448 - accuracy: 0.7962 - val_loss: 0.4235 - val_accuracy: 0.8106\n",
            "Epoch 6/100\n",
            "300/313 [===========================>..] - ETA: 0s - loss: 0.4366 - accuracy: 0.7985\n",
            "Epoch 00006: val_loss improved from 0.42351 to 0.41980, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4367 - accuracy: 0.7984 - val_loss: 0.4198 - val_accuracy: 0.8119\n",
            "Epoch 7/100\n",
            "306/313 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.7975\n",
            "Epoch 00007: val_loss did not improve from 0.41980\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4350 - accuracy: 0.7981 - val_loss: 0.4227 - val_accuracy: 0.8120\n",
            "Epoch 8/100\n",
            "299/313 [===========================>..] - ETA: 0s - loss: 0.4297 - accuracy: 0.8015\n",
            "Epoch 00008: val_loss improved from 0.41980 to 0.41831, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4298 - accuracy: 0.8012 - val_loss: 0.4183 - val_accuracy: 0.8193\n",
            "Epoch 9/100\n",
            "300/313 [===========================>..] - ETA: 0s - loss: 0.4275 - accuracy: 0.8017\n",
            "Epoch 00009: val_loss did not improve from 0.41831\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4283 - accuracy: 0.8015 - val_loss: 0.4439 - val_accuracy: 0.8080\n",
            "Epoch 10/100\n",
            "300/313 [===========================>..] - ETA: 0s - loss: 0.4235 - accuracy: 0.8043\n",
            "Epoch 00010: val_loss did not improve from 0.41831\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4236 - accuracy: 0.8040 - val_loss: 0.4214 - val_accuracy: 0.8173\n",
            "Epoch 11/100\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8021\n",
            "Epoch 00011: val_loss improved from 0.41831 to 0.40839, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4275 - accuracy: 0.8022 - val_loss: 0.4084 - val_accuracy: 0.8212\n",
            "Epoch 12/100\n",
            "306/313 [============================>.] - ETA: 0s - loss: 0.4223 - accuracy: 0.8045\n",
            "Epoch 00012: val_loss improved from 0.40839 to 0.40415, saving model to /content/drive/My Drive/IMDB_review_clf_Model\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/IMDB_review_clf_Model/assets\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4226 - accuracy: 0.8043 - val_loss: 0.4042 - val_accuracy: 0.8215\n",
            "Epoch 13/100\n",
            "301/313 [===========================>..] - ETA: 0s - loss: 0.4212 - accuracy: 0.8050\n",
            "Epoch 00013: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8048 - val_loss: 0.4558 - val_accuracy: 0.7791\n",
            "Epoch 14/100\n",
            "302/313 [===========================>..] - ETA: 0s - loss: 0.4212 - accuracy: 0.8052\n",
            "Epoch 00014: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4210 - accuracy: 0.8054 - val_loss: 0.4206 - val_accuracy: 0.8195\n",
            "Epoch 15/100\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.4167 - accuracy: 0.8083\n",
            "Epoch 00015: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8084 - val_loss: 0.4148 - val_accuracy: 0.8176\n",
            "Epoch 16/100\n",
            "304/313 [============================>.] - ETA: 0s - loss: 0.4159 - accuracy: 0.8092\n",
            "Epoch 00016: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8091 - val_loss: 0.4145 - val_accuracy: 0.8211\n",
            "Epoch 17/100\n",
            "305/313 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.8100\n",
            "Epoch 00017: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4161 - accuracy: 0.8098 - val_loss: 0.4099 - val_accuracy: 0.8178\n",
            "Epoch 18/100\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8087\n",
            "Epoch 00018: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4154 - accuracy: 0.8088 - val_loss: 0.4109 - val_accuracy: 0.8193\n",
            "Epoch 19/100\n",
            "304/313 [============================>.] - ETA: 0s - loss: 0.4123 - accuracy: 0.8101\n",
            "Epoch 00019: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.8095 - val_loss: 0.4077 - val_accuracy: 0.8208\n",
            "Epoch 20/100\n",
            "304/313 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.8093\n",
            "Epoch 00020: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4176 - accuracy: 0.8088 - val_loss: 0.4487 - val_accuracy: 0.7771\n",
            "Epoch 21/100\n",
            "304/313 [============================>.] - ETA: 0s - loss: 0.4132 - accuracy: 0.8104\n",
            "Epoch 00021: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8109 - val_loss: 0.4097 - val_accuracy: 0.8217\n",
            "Epoch 22/100\n",
            "303/313 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.8115\n",
            "Epoch 00022: val_loss did not improve from 0.40415\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4101 - accuracy: 0.8116 - val_loss: 0.4135 - val_accuracy: 0.8056\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_6VZFwFvtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cc92416-7701-4a89-a2e9-8fa8b6a1084c"
      },
      "source": [
        "# Evaluation.\n",
        "cls_test_model = tf.keras.models.load_model('/content/drive/My Drive/IMDB_review_clf_Model')\n",
        "score = cls_test_model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM84Wx1GFvrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1386007f-d1ea-4c2e-a481-b2ebda3b0b6b"
      },
      "source": [
        "# Prediction for some test datapoints.\n",
        "for i in range(10,101,10):\n",
        "\n",
        "  pred = cls_test_model.predict(X_test[i][None, :])\n",
        "  print('Actual =', y_test[i], 'Predicted =',np.round(pred,2))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual = 0 Predicted = [[0.4]]\n",
            "Actual = 1 Predicted = [[0.85]]\n",
            "Actual = 0 Predicted = [[0.71]]\n",
            "Actual = 1 Predicted = [[0.98]]\n",
            "Actual = 0 Predicted = [[0.1]]\n",
            "Actual = 1 Predicted = [[0.5]]\n",
            "Actual = 1 Predicted = [[0.48]]\n",
            "Actual = 1 Predicted = [[0.6]]\n",
            "Actual = 0 Predicted = [[0.29]]\n",
            "Actual = 0 Predicted = [[0.15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BhKGDNoFvp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}